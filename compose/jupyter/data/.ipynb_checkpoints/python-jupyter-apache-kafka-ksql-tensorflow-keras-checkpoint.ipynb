{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Integration + Preprocessing / Interactive Analysis with KSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the combination of Python, Apache Kafka, KSQL for Machine Learning infrastructures. \n",
    "\n",
    "It includes code examples using ksql-python and other widespread components from Python’s machine learning ecosystem, like Numpy, pandas, TensorFlow and Keras. \n",
    "\n",
    "The use case is fraud detection for credit card payments. We use a test data set from Kaggle as foundation to train an unsupervised autoencoder to detect anomalies and potential fraud in payments. Focus of this example is not just model training, but the whole Machine Learning infrastructure including data ingestion, data preprocessing, model training, model deployment and monitoring. All of this needs to be scalable, reliable and performant.\n",
    "\n",
    "If you want to learn more about the relation between the Apache Kafka open source ecosystem and Machine Learning, please check out these two blog posts:\n",
    "\n",
    "- [How to Build and Deploy Scalable Machine Learning in Production with Apache Kafka](https://www.confluent.io/blog/build-deploy-scalable-machine-learning-production-apache-kafka/)\n",
    "- [Using Apache Kafka to Drive Cutting-Edge Machine Learning](https://www.confluent.io/blog/using-apache-kafka-drive-cutting-edge-machine-learning)\n",
    "\n",
    "##### This notebook is not meant to be perfect using all coding and ML best practices, but just a simple guide how to build your own notebooks where you can combine Python APIs with Kafka and KSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration and Preprocessing with Python and KSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "\u001b[K     |████████████████████████████████| 246 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --force-reinstall kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksql import KSQLAPI\n",
    "client = KSQLAPI('http://ksqldb-server:8088')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['broker:29092'],\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x7f33a6b10940>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producer.send('transactions', value={\n",
    "    'transaction_id': \"RF\" + str(fake.pyint(5)),\n",
    "    'transaction_type': \"transaction_\" + str(fake.pyint(1)),\n",
    "    'from_account': fake.iban(),\n",
    "    'to_account': fake.iban(),\n",
    "    'amount_cents': fake.pyint(),\n",
    "    'created_at': fake.date_time().strftime(\"%Y/%m/%d, %H:%M:%S\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consume source data from Kafka Topic \"creditcardfraud_source\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KSQLError",
     "evalue": "(\"Cannot add stream 'TRANSACTIONS': A stream with the same name already exists\", 40001, [])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, endpoint, method, sql_string, stream_properties, encoding)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKSQLError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-bc4b0d9ad531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m client.create_stream(table_name='TRANSACTIONS',\n\u001b[0m\u001b[1;32m      2\u001b[0m                      columns_type=['transaction_id string',\n\u001b[1;32m      3\u001b[0m                                    \u001b[0;34m'transaction_type string'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    \u001b[0;34m'from_account string'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                    \u001b[0;34m'to_account string'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/client.py\u001b[0m in \u001b[0;36mcreate_stream\u001b[0;34m(self, table_name, columns_type, topic, value_format)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"JSON\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         return self.sa.create_stream(\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mtable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36mcreate_stream\u001b[0;34m(self, table_name, columns_type, topic, value_format)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"JSON\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         return self._create(\n\u001b[0m\u001b[1;32m    266\u001b[0m             \u001b[0mtable_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mtable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(self, table_type, table_name, columns_type, topic, value_format, key)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         )\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mksql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mksql_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36mksql\u001b[0;34m(self, ksql_string, stream_properties)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mksql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksql_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_properties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ksql\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksql_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_properties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_properties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, endpoint, method, sql_string, stream_properties, encoding)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKSQLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"message\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error_code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stackTrace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKSQLError\u001b[0m: (\"Cannot add stream 'TRANSACTIONS': A stream with the same name already exists\", 40001, [])"
     ]
    }
   ],
   "source": [
    "client.create_stream(table_name='TRANSACTIONS',\n",
    "                     columns_type=['transaction_id string',\n",
    "                                   'transaction_type string',\n",
    "                                   'from_account string',\n",
    "                                   'to_account string',\n",
    "                                   'amount_cents integer',\n",
    "                                   'created_at string'],\n",
    "                     topic='transactions',\n",
    "                     value_format='JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a materialized table (no high level method available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@type': 'currentStatus',\n",
       "  'statementText': \"CREATE TABLE AGG WITH (KAFKA_TOPIC='AGG', PARTITIONS=1, REPLICAS=1) AS SELECT\\n  TRANSACTIONS.FROM_ACCOUNT FROM_ACCOUNT,\\n  COUNT(*) NUM_TRANSACTIONS,\\n  SUM(TRANSACTIONS.AMOUNT_CENTS) TOTAL_VALUE\\nFROM TRANSACTIONS TRANSACTIONS\\nGROUP BY TRANSACTIONS.FROM_ACCOUNT\\nEMIT CHANGES;\",\n",
       "  'commandId': 'table/`AGG`/create',\n",
       "  'commandStatus': {'status': 'SUCCESS',\n",
       "   'message': 'Created query with ID CTAS_AGG_0'},\n",
       "  'commandSequenceNumber': 2,\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = \"\"\"CREATE TABLE agg AS\n",
    "  SELECT transaction_type, COUNT(*) AS num_transactions, SUM(amount_cents) AS total_value\n",
    "  FROM TRANSACTIONS GROUP BY transaction_type EMIT CHANGES\n",
    "  \"\"\"\n",
    "\n",
    "client.ksql(qr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: \n",
    "\n",
    "- Filter columns which are not needed \n",
    "- Filter messages where column 'class' is empty\n",
    "- Change data format to Avro for more convenient further processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_stream_as(table_name='transactions_high',\n",
    "                     select_columns=['transaction_id', 'transaction_id', 'from_account', 'to_account', 'amount_cents', 'created_at'],\n",
    "                     src_table='transactions',\n",
    "                     conditions='amount_cents > 5000',\n",
    "                     kafka_topic='transactions_high',\n",
    "                     value_format='JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the creates KSQL Streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@type': 'streams',\n",
       "  'statementText': 'show streams;',\n",
       "  'streams': [{'type': 'STREAM',\n",
       "    'name': 'TRANSACTIONS',\n",
       "    'topic': 'transactions',\n",
       "    'format': 'JSON'},\n",
       "   {'type': 'STREAM',\n",
       "    'name': 'TRANSACTIONS_HIGH',\n",
       "    'topic': 'transactions_high',\n",
       "    'format': 'JSON'}],\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql('show streams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the metadata of the KSQL Stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@type': 'sourceDescription',\n",
       "  'statementText': 'describe TRANSACTIONS_HIGH;',\n",
       "  'sourceDescription': {'name': 'TRANSACTIONS_HIGH',\n",
       "   'windowType': None,\n",
       "   'readQueries': [],\n",
       "   'writeQueries': [{'queryString': \"CREATE STREAM TRANSACTIONS_HIGH WITH (KAFKA_TOPIC='transactions_high', PARTITIONS=1, REPLICAS=1, VALUE_FORMAT='JSON') AS SELECT\\n  TRANSACTIONS.TRANSACTION_ID TRANSACTION_ID,\\n  TRANSACTIONS.FROM_ACCOUNT FROM_ACCOUNT,\\n  TRANSACTIONS.TO_ACCOUNT TO_ACCOUNT,\\n  TRANSACTIONS.AMOUNT_CENTS AMOUNT_CENTS,\\n  TRANSACTIONS.CREATED_AT CREATED_AT\\nFROM TRANSACTIONS TRANSACTIONS\\nWHERE (TRANSACTIONS.AMOUNT_CENTS > 5000)\\nEMIT CHANGES;\",\n",
       "     'sinks': ['TRANSACTIONS_HIGH'],\n",
       "     'sinkKafkaTopics': ['transactions_high'],\n",
       "     'id': 'CSAS_TRANSACTIONS_HIGH_3',\n",
       "     'state': 'RUNNING'}],\n",
       "   'fields': [{'name': 'ROWTIME',\n",
       "     'schema': {'type': 'BIGINT', 'fields': None, 'memberSchema': None}},\n",
       "    {'name': 'ROWKEY',\n",
       "     'schema': {'type': 'STRING', 'fields': None, 'memberSchema': None}},\n",
       "    {'name': 'TRANSACTION_ID',\n",
       "     'schema': {'type': 'STRING', 'fields': None, 'memberSchema': None}},\n",
       "    {'name': 'FROM_ACCOUNT',\n",
       "     'schema': {'type': 'STRING', 'fields': None, 'memberSchema': None}},\n",
       "    {'name': 'TO_ACCOUNT',\n",
       "     'schema': {'type': 'STRING', 'fields': None, 'memberSchema': None}},\n",
       "    {'name': 'AMOUNT_CENTS',\n",
       "     'schema': {'type': 'INTEGER', 'fields': None, 'memberSchema': None}},\n",
       "    {'name': 'CREATED_AT',\n",
       "     'schema': {'type': 'STRING', 'fields': None, 'memberSchema': None}}],\n",
       "   'type': 'STREAM',\n",
       "   'key': '',\n",
       "   'timestamp': '',\n",
       "   'statistics': '',\n",
       "   'errorStats': '',\n",
       "   'extended': False,\n",
       "   'keyFormat': 'KAFKA',\n",
       "   'valueFormat': 'JSON',\n",
       "   'topic': 'transactions_high',\n",
       "   'partitions': 0,\n",
       "   'replication': 0,\n",
       "   'statement': \"CREATE STREAM TRANSACTIONS_HIGH WITH (KAFKA_TOPIC='transactions_high', PARTITIONS=1, REPLICAS=1, VALUE_FORMAT='JSON') AS SELECT\\n  TRANSACTIONS.TRANSACTION_ID TRANSACTION_ID,\\n  TRANSACTIONS.FROM_ACCOUNT FROM_ACCOUNT,\\n  TRANSACTIONS.TO_ACCOUNT TO_ACCOUNT,\\n  TRANSACTIONS.AMOUNT_CENTS AMOUNT_CENTS,\\n  TRANSACTIONS.CREATED_AT CREATED_AT\\nFROM TRANSACTIONS TRANSACTIONS\\nWHERE (TRANSACTIONS.AMOUNT_CENTS > 5000)\\nEMIT CHANGES;\"},\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql('describe TRANSACTIONS_HIGH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materialized Views ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive query statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7385\n"
     ]
    }
   ],
   "source": [
    " \n",
    "res = \"\"\"{\"row\":{\"columns\":[1610726138178,null,\"RF12111\",\"GB85XZQL75965818871538\",\"GB80IUYD16603233079843\",7385,\"1983/04/18, 07:44:25\"]}},\n",
    "\"\"\"\n",
    "\n",
    "jres = json.loads(res[:-2])\n",
    "\n",
    "print(jres[\"row\"][\"columns\"][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"header\":{\"queryId\":\"none\",\"schema\":\"`ROWTIME` BIGINT, `ROWKEY` STRING, `TRANSACTION_ID` STRING, `FROM_ACCOUNT` STRING, `TO_ACCOUNT` STRING, `AMOUNT_CENTS` INTEGER, `CREATED_AT` STRING\"}},\n",
      "\n",
      "Wrong input\n",
      "{\"row\":{\"columns\":[1610726738648,null,\"RF12111\",\"GB50IBJR22487336967086\",\"GB09XOFD99607821552687\",6102,\"1993/03/23, 00:51:57\"]}},\n",
      "\n",
      "{'row': {'columns': [1610726738648, None, 'RF12111', 'GB50IBJR22487336967086', 'GB09XOFD99607821552687', 6102, '1993/03/23, 00:51:57']}}\n",
      "6102\n",
      "{\"row\":{\"columns\":[1610726748658,null,\"RF12111\",\"GB08SUDH80502780225462\",\"GB35ERUG12988263309228\",9692,\"2019/07/08, 07:18:27\"]}},\n",
      "\n",
      "{'row': {'columns': [1610726748658, None, 'RF12111', 'GB08SUDH80502780225462', 'GB35ERUG12988263309228', 9692, '2019/07/08, 07:18:27']}}\n",
      "9692\n",
      "{\"row\":{\"columns\":[1610726758667,null,\"RF12111\",\"GB82LKGF46742641610938\",\"GB35DDRP54866558844629\",8089,\"1992/12/21, 00:26:29\"]}},\n",
      "\n",
      "{'row': {'columns': [1610726758667, None, 'RF12111', 'GB82LKGF46742641610938', 'GB35DDRP54866558844629', 8089, '1992/12/21, 00:26:29']}}\n",
      "8089\n",
      "{\"row\":{\"columns\":[1610726768674,null,\"RF12111\",\"GB23LKPC50313144448122\",\"GB38SGOE54813097134902\",6387,\"2000/08/19, 23:30:59\"]}},\n",
      "\n",
      "{'row': {'columns': [1610726768674, None, 'RF12111', 'GB23LKPC50313144448122', 'GB38SGOE54813097134902', 6387, '2000/08/19, 23:30:59']}}\n",
      "6387\n",
      "{\"row\":{\"columns\":[1610726788679,null,\"RF12111\",\"GB68KXBT18037332841364\",\"GB15JSMS04389887863290\",9380,\"1990/12/07, 19:06:56\"]}},\n",
      "\n",
      "{'row': {'columns': [1610726788679, None, 'RF12111', 'GB68KXBT18037332841364', 'GB15JSMS04389887863290', 9380, '1990/12/07, 19:06:56']}}\n",
      "9380\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-db3e36aa5ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM TRANSACTIONS_HIGH EMIT CHANGES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_string, encoding, chunk_size, stream_properties, idle_timeout, use_http2, return_objects)\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/utils.py\u001b[0m in \u001b[0;36mprocess_query_result\u001b[0;34m(results, return_objects)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_objects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# parse rows into objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_string, encoding, chunk_size, stream_properties, idle_timeout)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreaming_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstreaming_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mstart_idle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = client.query('SELECT * FROM TRANSACTIONS_HIGH EMIT CHANGES')\n",
    "\n",
    "for item in query: \n",
    "    print(item)\n",
    "    try:\n",
    "        jres = json.loads(item[:-2])\n",
    "        print(jres)\n",
    "        print(jres[\"row\"][\"columns\"][5])\n",
    "    except:\n",
    "        print(\"Wrong input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional (optional) analysis and preprocessing examples\n",
    "\n",
    "Some more examples for possible data wrangling and preprocessing with KSQL:\n",
    "\n",
    "- Anonymization\n",
    "- Augmentation\n",
    "- Merge / Join data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"header\":{\"queryId\":\"none\",\"schema\":\"`TRANSACTION_ID` STRING, `KSQL_COL_1` STRING\"}},\n",
      "\n",
      "{\"row\":{\"columns\":[\"RF12111\",\"XX94RQMU23438827339470\"]}},\n",
      "\n",
      "{\"row\":{\"columns\":[\"RF12111\",\"XX83WIKR43447254751484\"]}},\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-c331f15c97c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT transaction_id, MASK_LEFT(from_account, 2) FROM TRANSACTIONS EMIT CHANGES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_string, encoding, chunk_size, stream_properties, idle_timeout, use_http2, return_objects)\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/utils.py\u001b[0m in \u001b[0;36mprocess_query_result\u001b[0;34m(results, return_objects)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_objects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# parse rows into objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/api.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_string, encoding, chunk_size, stream_properties, idle_timeout)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreaming_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstreaming_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mstart_idle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = client.query('SELECT transaction_id, MASK_LEFT(from_account, 2) FROM TRANSACTIONS EMIT CHANGES')\n",
    "\n",
    "for item in query: \n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping from KSQL to NumPy / pandas for Machine Learning tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below command returns a Python generator. It can be printed e.g. by reading its values via next(query) or a for loop.\n",
    "\n",
    "Due to a current [bug in ksql-python library](https://github.com/bryanyang0528/ksql-python/issues/57), we need to to an additional line of Python code to strip out unnecessary info and change to 2D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"header\":{\"queryId\":\"query_1610381453023\",\"schema\":\"`ROWKEY` STRING KEY, `ROWTIME` BIGINT, `FROM_ACCOUNT` STRING, `KSQL_COL_1` BIGINT, `KSQL_COL_2` INTEGER\"}},\n",
      "\n",
      "{\"row\":{\"columns\":[\"GB17TBKQ74645344152028\",1610379209486,\"GB17TBKQ74645344152028\",1,6784]}}]\n",
      "^^ final result ^^\n"
     ]
    }
   ],
   "source": [
    "query = client.query('select * from AGG WHERE ROWKEY = \\'GB17TBKQ74645344152028\\'') # Returns a Python generator object\n",
    "\n",
    "try:\n",
    "    for item in query:\n",
    "        print(item)\n",
    "except RuntimeError:\n",
    "    print(\"^^ final result ^^\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/utils.py\u001b[0m in \u001b[0;36mprocess_query_result\u001b[0;34m(results, return_objects)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# parse rows into objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-d53b4c9a02d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#df = pd.DataFrame(data=data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n\\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#data = r['row']['columns'][2] for r in records\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ksql/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_string, encoding, chunk_size, stream_properties, idle_timeout, use_http2, return_objects)\u001b[0m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess_query_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "query = client.query('select * from AGG WHERE ROWKEY=\\'GB73ZPWA03514126591488\\';') # Returns a Python generator object\n",
    "\n",
    "#items = [item for item in query][:-1]        # -1 to remove last record that is a dummy msg for \"Limit Reached\"          \n",
    "#one_record = json.loads(''.join(items))      # Join two records as one as ksql-python is splitting it into two?          \n",
    "#data = [one_record['row']['columns'][2:-1]]  # Strip out unnecessary info and change to 2D array                     \n",
    "#df = pd.DataFrame(data=data)   \n",
    "\n",
    "records = [json.loads(r) for r in ''.join(query).strip().replace('\\n\\n\\n\\n', '').split('\\n')]\n",
    "data = [r['row']['columns'][2:] for r in records[:-1]]\n",
    "#data = r['row']['columns'][2] for r in records\n",
    "df = pd.DataFrame(data=data, columns=['transaction_id', 'from_account', 'to_account', 'amount_cents', 'created_at'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: redis-cli: command not found\r\n",
      "cat: write error: Broken pipe\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -3] Temporary failure in name resolution. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "WARNING:kafka.conn:DNS lookup failed for broker:29092, exception was [Errno -2] Name or service not known. Is your advertised.listeners (called advertised.host.name before Kafka 9) correct and resolvable?\n",
      "ERROR:kafka.conn:DNS lookup failed for broker:29092 (AddressFamily.AF_UNSPEC)\n",
      "ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=1 host=broker:29092 <connecting> [IPv4 ('172.30.0.11', 29092)]> returned error 111. Disconnecting.\n",
      "WARNING:kafka.client:Node 1 connection failed -- refreshing metadata\n",
      "ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=1 host=broker:29092 <connecting> [IPv4 ('172.30.0.11', 29092)]> returned error 111. Disconnecting.\n",
      "WARNING:kafka.client:Node 1 connection failed -- refreshing metadata\n",
      "ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=1 host=broker:29092 <connecting> [IPv4 ('172.30.0.11', 29092)]> returned error 111. Disconnecting.\n",
      "WARNING:kafka.client:Node 1 connection failed -- refreshing metadata\n"
     ]
    }
   ],
   "source": [
    "! cat example_data | redis-cli --pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some test data \n",
    "\n",
    "As discussed in the step-by-step guide, you have various options. Here we - ironically - read messages from a CSV file. This is for simple demo purposes so that you don't have to set up a real continuous Kafka stream. \n",
    "\n",
    "In real world or more advanced examples, you should connect to a real Kafka data stream (for instance using the Kafka data generator or Kafka Connect).\n",
    "\n",
    "Here we just consume a few messages for demo purposes so that they get mapped into a pandas dataframe:\n",
    "\n",
    "                cat /Users/kai.waehner/git-projects/python-jupyter-apache-kafka-ksql-tensorflow-keras/data/creditcard_extended.csv | kafka-console-producer --broker-list localhost:9092 --topic creditcardfraud_source\n",
    "                \n",
    "You need to do this from command line because Jupyter cannot execute this in parallel to above KSQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with Pandas + Model Training with TensorFlow / Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BE AWARE: You need enough messages in the pandas data frame to train the model in the below cells (if you just play around with ksql-python and just add a few Kafka events, it is not a sufficient number of rows to continue. You can simply change to df = pd.read_csv(\"data/creditcard.csv\") as shown below in this case to get a bigger data set...\n",
    "\n",
    "\n",
    "This part only includes the steps required for model training of the Autoencoder with Keras and TensorFlow. \n",
    "\n",
    "If you want to get a better understanding of the model, take a look at the other notebook [Python Tensorflow Keras Fraud Detection Autoencoder.ipynb](http://localhost:8888/notebooks/Python%20Tensorflow%20Keras%20Fraud%20Detection%20Autoencoder.ipynb) which includes many more details, plots and explanations.\n",
    "\n",
    "[Kudos to David Ellison](https://www.datascience.com/blog/fraud-detection-with-tensorflow).\n",
    "\n",
    "[The credit card fraud data set is available at Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "# matplotlib inline\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pylab import rcParams\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the dataframe from above (imported and preprocessed with KSQL)\n",
    "\n",
    "# As alternative directly import from a CSV file (\"the normal approach without Kafka and streaming data\")\n",
    "\n",
    "# \"data/creditcard_small.csv\" is a very small data set (just for quick demo purpose to get a model binary)\n",
    "# => replace with \"data/creditcard.csv\" to use a real data set to train a model with good accuracy\n",
    "#df = pd.read_csv(\"data/creditcard.csv\") \n",
    "\n",
    "\n",
    "df.head(n=5) #just to check you imported the dataset properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed and percentage of test data\n",
    "RANDOM_SEED = 314 #used to help randomly select the data points\n",
    "TEST_PCT = 0.2 # 20% of the data\n",
    "\n",
    "#set up graphic style in this case I am using the color scheme from xkcd.com\n",
    "rcParams['figure.figsize'] = 14, 8.7 # Golden Mean\n",
    "LABELS = [\"Normal\",\"Fraud\"]\n",
    "#col_list = [\"cerulean\",\"scarlet\"]# https://xkcd.com/color/rgb/\n",
    "#sns.set(style='white', font_scale=1.75, palette=sns.xkcd_palette(col_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = [df.Class == 0] #save normal_df observations into a separate df\n",
    "fraud_df = [df.Class == 1] #do the same for frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df.drop(['Time'], axis=1) #if you think the var is unimportant\n",
    "df_norm = df\n",
    "df_norm['Time'] = StandardScaler().fit_transform(df_norm['Time'].values.reshape(-1, 1))\n",
    "df_norm['Amount'] = StandardScaler().fit_transform(df_norm['Amount'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(df_norm, test_size=TEST_PCT, random_state=RANDOM_SEED)\n",
    "train_x = train_x[train_x.Class == 0] #where normal transactions\n",
    "train_x = train_x.drop(['Class'], axis=1) #drop the class column\n",
    "\n",
    "test_y = test_x['Class'] #save the class column for the test set\n",
    "test_x = test_x.drop(['Class'], axis=1) #drop the class column\n",
    "\n",
    "train_x = train_x.values #transform to ndarray\n",
    "test_x = test_x.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Jupyter Notebook crashed sometimes in the next step 'model training' (probably memory issues):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of epochs and batch_size if your Jupyter crashes (due to memory issues)\n",
    "# nb_epoch = 100\n",
    "# batch_size = 128\n",
    "nb_epoch = 5\n",
    "batch_size = 32\n",
    "\n",
    "input_dim = train_x.shape[1] #num of columns, 30\n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) #i.e. 7\n",
    "learning_rate = 1e-7\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"models/autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_x, test_x),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('models/autoencoder_fraud.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_predictions = autoencoder.predict(test_x)\n",
    "mse = np.mean(np.power(test_x - test_x_predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
    "                        'True_class': test_y})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary 'models/autoencoder_fraud.h5' is the trained model which can then be deployed anywhere to do prediction on new incoming events in real time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "This demo focuses on the combination of Python and KSQL for data preprocessing and model training. If you want to understand the relation between Apache Kafka, KSQL and Python-related Machine Learning tools like TensorFlow for model deployment and monitoring, please check out my other Github projects:\n",
    "\n",
    "Some examples of model deployment in Kafka environments:\n",
    "\n",
    "- [Analytic models (TensorFlow, Keras, H2O and Deeplearning4j) embedded in Kafka Streams microservices](https://github.com/kaiwaehner/kafka-streams-machine-learning-examples)\n",
    "- [Anomaly detection of IoT sensor data with a model embedded into a KSQL UDF](https://github.com/kaiwaehner/ksql-udf-deep-learning-mqtt-iot)\n",
    "- [RPC communication between Kafka Streams application and model server (TensorFlow Serving)](https://github.com/kaiwaehner/tensorflow-serving-java-grpc-kafka-streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine with Redis Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add data to redis instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data transferred. Waiting for the last reply...\r\n",
      "Last reply received from server.\r\n",
      "errors: 0, replies: 10\r\n"
     ]
    }
   ],
   "source": [
    "! cat example_data | redis-cli --pipe -h redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis\n",
      "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 682 kB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "Successfully installed redis-3.5.3\n"
     ]
    }
   ],
   "source": [
    "! pip install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host=\"redis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'cat_6'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get(\"transaction_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oracle Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cx_Oracle\n",
      "  Downloading cx_Oracle-8.1.0-cp38-cp38-manylinux1_x86_64.whl (825 kB)\n",
      "\u001b[K     |████████████████████████████████| 825 kB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: cx-Oracle\n",
      "Successfully installed cx-Oracle-8.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ORACLE_HOME\"] = \"/opt/oracle/instantclient_19_8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/oracle/instantclient_19_8'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"ORACLE_HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "\n",
    "dsn_tns = cx_Oracle.makedsn('oracledb', '1521', service_name='xe') # if needed, place an 'r' before any parameter in order to address special characters such as '\\'.\n",
    "conn = cx_Oracle.connect(user=r'system', password='oracle', dsn=dsn_tns) # if needed, place an 'r' before any parameter in order to address special characters such as '\\'. For example, if your user name contains '\\', you'll need to place 'r' before the user name: user=r'User Name'\n",
    "query = \"\"\"select * from ALL_USERS\"\"\"\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute(query) # use triple quotes if you want to spread your query across multiple lines\n",
    "for row in c:\n",
    "    print (row[0], '-', row[1]) # this only shows the first two columns. To add an additional column you'll need to add , '-', row[2], etc.\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Pandas analysis with above Fraud Detection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a minute or two (big CSV file)...\n",
    "#df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
